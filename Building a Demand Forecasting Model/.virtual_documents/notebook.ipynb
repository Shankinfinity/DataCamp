





# Import required libraries
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml import Pipeline
from pyspark.ml.regression import RandomForestRegressor
from pyspark.sql.functions import col, dayofmonth, month, year,  to_date, to_timestamp, weekofyear, dayofweek
from pyspark.ml.feature import StringIndexer
from pyspark.ml.evaluation import RegressionEvaluator

# Initialize Spark session
my_spark = SparkSession.builder.appName("SalesForecast").getOrCreate()

# Importing sales data
sales_data = my_spark.read.csv(
    "Online Retail.csv", header=True, inferSchema=True, sep=",")

# Convert InvoiceDate to datetime 
sales_data = sales_data.withColumn("InvoiceDate", to_date(
    to_timestamp(col("InvoiceDate"), "d/M/yyyy H:mm")))


sales_data.show()


sales_data.printSchema()


sales_data.summary().show()


sales_data.describe().show()


from pyspark.sql import functions as F

sales_data = sales_data.withColumn("Year", F.year("InvoiceDate")) \
                        .withColumn("Month", F.month("InvoiceDate")) \
                        .withColumn("Day", F.dayofmonth("InvoiceDate")) \
                        .withColumn("Week", F.weekofyear("InvoiceDate")) \
                        .withColumn("DayOfWeek", F.date_format("InvoiceDate", "E"))

daily_sales = sales_data.groupBy(
    "Country", "StockCode", "InvoiceDate", "Year", "Month", "Day", "Week", "DayOfWeek"
).agg(
    {"Quantity": "sum", "UnitPrice": "avg"}
)
daily_sales = daily_sales.withColumnRenamed("sum(Quantity)", "Quantity") \
                            .withColumnRenamed("avg(UnitPrice)", "AvgUnitPrice")
daily_sales.show(10)


split_date = "2011-09-25"

train_data = daily_sales.filter(F.col("InvoiceDate") <= F.lit(split_date))
test_data = daily_sales.filter(F.col("InvoiceDate") > F.lit(split_date))

pd_daily_train_data = train_data.toPandas()


print("Train data max date:", train_data.agg(F.max("InvoiceDate")).collect()[0][0])
print("Test data min date:", test_data.agg(F.min("InvoiceDate")).collect()[0][0])



country_indexer = StringIndexer(
    inputCol="Country",
    outputCol="CountryIndex"
).setHandleInvalid("keep")

stock_code_indexer = StringIndexer(
    inputCol="StockCode",
    outputCol="StockCodeIndex"
).setHandleInvalid("keep")



assembler = VectorAssembler(
    inputCols=["CountryIndex", "StockCodeIndex", "Year", "Month", "Day", "Week", "AvgUnitPrice"],
    outputCol="features"
)



rf = RandomForestRegressor(
    featuresCol="features",
    labelCol="Quantity",
    maxBins=4000
)

pipeline = Pipeline(stages=[country_indexer, stock_code_indexer, assembler, rf])
model = pipeline.fit(train_data)



test_predictions = model.transform(test_data)
test_predictions = test_predictions.withColumn("prediction", col("prediction").cast("double"))



mae_evaluator = RegressionEvaluator(
    labelCol="Quantity",
    predictionCol="prediction",
    metricName="mae"
)
mae = mae_evaluator.evaluate(test_predictions)

print("Mean Absolute Error (MAE):", mae)


weekly_sales = test_predictions.groupBy("Year", "Week").agg(
    F.sum("prediction").alias("TotalPredictedQuantity")
)

week_39_sales = weekly_sales.filter((F.col("Year") == 2011) & (F.col("Week") == 39))
quantity_sold_w39 = int(week_39_sales.select("TotalPredictedQuantity").collect()[0][0])
print("Predicted quantity sold in Week 39 of 2011:", quantity_sold_w39)
